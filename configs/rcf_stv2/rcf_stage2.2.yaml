# Note: By default, this config uses trainval as training

# Uses pre-extracted flows.
batch_size: 8
epochs: 20
learning_rate: 1.e-5
optimizer: Adam
weight_decay: 5.e-6


workers: 16

checkpoints_dir: saved_stv2/saved_rcf_stage2.2
preferred_linalg_library: cusolver
model_cls: RCFModel

eval_pos_th: 0.35

disable_wandb: true
allow_overwriting_checkpoints_dir: false

train_transform_kwargs:
  strong_aug: true
  has_pl: true

test_transform_kwargs:
  strong_aug: false

loss_log_interval: 100

# Use SegTrackv2 as training set
data_path: ./data/data_SegTrackv2_resized
dataset_kwargs: {}

train_dataset_kwargs:
  frame_num: 2
  load_flow: true
  flow_suffix: "_NewCT"
  split: trainval.txt
  zero_ann: false
  load_pl: true
  pl_root: saved_stv2/saved_rcf_stage2.1/saved_eval_export_ema_torchcrf_ncut_torchcrf/0

test_dataset_kwargs:
  frame_num: 1
  load_flow: false
  split: trainval.txt
  zero_ann: false

lr_scheduler_kwargs:
  # policy: 'poly'
  power: 0.9
  min_lr: 1.e-6

# Get object channel after 1 epoch
set_object_channel_after_epoch: 2

# Note that we use mixed precision
trainer_kwargs:
  check_val_every_n_epoch: 1
  precision: 16

model_kwargs:
  # Smaller segmentation loss from motion
  w_seg: 0.1
  # Use entropy and do not use sharpen
  w_sharpen: 0
  w_entropy: 0
  # Use different last convolution for fw and bw residual
  separate_residual: true
  # Use PL
  w_pl: 2.0
  pl_pos_weight: 2.
  pl_neg_weight: 1.
  mask_layer: 4
  align_corners: false
  # The mask is 96x96 (we crop 384x384)
  mask_size: [96, 96]
  allow_mask_resize: false
  # Enable residual and clamp
  backbone2:
    dilations: [1, 1, 2, 4]
    strides: [1, 2, 1, 1]
    type: ResNet
    depth: 50
    num_stages: 4
    out_indices: [0, 1, 2, 3]
    norm_cfg: &id001
      type: SyncBN
      requires_grad: true
    norm_eval: false
    style: pytorch
    contract_dilation: true
    create_ema: false
  # Enable residual and clamp
  decode_head:
    ssim_sz: 1
    create_flownet: true
    mask_layer: 4
    type: FlowAggregationHeadWithResidual
    flow_feat_before_agg_kernel_size: 3
    num_flow_feat_channels: 64
    mask_size: [96, 96]
    norm_flow: false
    # Use clamp 20
    clamp_flow_t: 20.
    free_residual: false
    free_residual_with_affine: true
    free_scale: false
    outlier_robust_loss: false
    eps: 0.01
    q: 0.4
    allow_residual_resize: true
    residual_adjustment_scale: 10.
    # Default value: put here to allow overriding from command line
    # This is the division coefficient before tanh.
    pred_div_coeff: 10.
  decode_head2:
    # Input is resized to 384x384.
    concat_input: false
    dilation: 6
    channels: 256
    type: FCNHead
    input_transform: resize_concat
    in_channels: [256, 2048]
    in_index: [0, 3]
    num_convs: 2
    dropout_ratio: 0.1
    num_classes: 4
    create_ema: false
    norm_cfg: *id001
    align_corners: false
    loss_decode:
      type: CrossEntropyLoss
      use_sigmoid: false
      loss_weight: 1.0
  decode_head3:
    concat_input: false
    dilation: 6
    channels: 256
    type: FCNHead
    in_channels: 4096
    # Only use the last map
    in_index: -1
    num_convs: 2
    dropout_ratio: 0.1
    # in_channel is 4096 (2048 * 2 as we have two frames) as in the original one
    # Predicted residual is 48x48, resize in `decode_head` with `allow_residual_resize`
    # Output dimension is 16 because we need to split to fw and bw
    num_classes: 16
    norm_cfg: *id001
    align_corners: false
    loss_decode:
      type: CrossEntropyLoss
      use_sigmoid: false
      loss_weight: 1.0

eval_save: true
# export depends on save
eval_export: true
export_all_seg: true

# We drop `decode_head2` since the model loaded does not use 2x head.
drop_head_decode_head2: true

# Please set:
object_channel: 0
pretrained_model: saved_stv2/saved_rcf_stage1/last.ckpt
