# Note: By default, this config uses trainval as training

# Uses pre-extracted flows.
batch_size: 8
epochs: 20
learning_rate: 1.e-4
optimizer: Adam
weight_decay: 1.e-6

workers: 16

checkpoints_dir: saved_stv2/saved_rcf_stage1
preferred_linalg_library: do_not_set
pretrained_model: data/pretrained/densecl_r50_imagenet_200ep.pth
model_cls: RCFModel

eval_pos_th: 0.35

disable_wandb: true
allow_overwriting_checkpoints_dir: false

train_transform_kwargs:
  strong_aug: true

test_transform_kwargs:
  strong_aug: false

loss_log_interval: 100

object_channel: null

# Use SegTrackv2 as training set
data_path: ./data/data_SegTrackv2_resized
dataset_kwargs: {}

train_dataset_kwargs:
  frame_num: 2
  load_flow: true
  flow_suffix: "_NewCT"
  split: trainval.txt
  zero_ann: false

test_dataset_kwargs:
  frame_num: 1
  load_flow: false
  split: trainval.txt
  zero_ann: false

lr_scheduler_kwargs:
  # policy: 'poly'
  power: 0.9
  min_lr: 1.e-6

# Get object channel after 1 epoch
set_object_channel_after_epoch: 2

# Note that we use mixed precision
trainer_kwargs:
  check_val_every_n_epoch: 1
  precision: 16
  # Enable cudnn benchmark
  benchmark: true

model_kwargs:
  w_seg: 1.0
  # Use entropy and do not use sharpen
  w_sharpen: 0
  w_entropy: 0.05
  # Use different last convolution for fw and bw residual
  separate_residual: true
  mask_layer: 4
  align_corners: false
  # The mask is 48x48 (we crop 384x384)
  mask_size: [48, 48]
  allow_mask_resize: false
  # Enable residual and clamp
  backbone2:
    dilations: [1, 1, 2, 4]
    strides: [1, 2, 1, 1]
    type: ResNet
    depth: 50
    num_stages: 4
    out_indices: [0, 1, 2, 3]
    norm_cfg: &id001
      type: SyncBN
      requires_grad: true
    norm_eval: false
    style: pytorch
    # Changed to v2.1
    # contract_dilation: false
    contract_dilation: true
  decode_head:
    ssim_sz: 1
    create_flownet: true
    mask_layer: 4
    type: FlowAggregationHeadWithResidual
    flow_feat_before_agg_kernel_size: 3
    num_flow_feat_channels: 64
    mask_size: [48, 48]
    norm_flow: false
    # Use clamp 20
    clamp_flow_t: 20.
    free_residual: false
    free_residual_with_affine: true
    free_scale: false
    outlier_robust_loss: false
    eps: 0.01
    q: 0.4
    allow_residual_resize: false
    residual_adjustment_scale: 10.
    # Default value: put here to allow overriding from command line
    # This is the division coefficient before tanh.
    pred_div_coeff: 10.
  decode_head2:
    # Input is resized to 384x384.
    concat_input: false
    dilation: 6
    channels: 256
    type: FCNHead
    in_channels: 2048
    in_index: 3
    num_convs: 2
    dropout_ratio: 0.1
    num_classes: 4
    norm_cfg: *id001
    align_corners: false
    loss_decode:
      type: CrossEntropyLoss
      use_sigmoid: false
      loss_weight: 1.0
  decode_head3:
    concat_input: false
    dilation: 6
    channels: 256
    type: FCNHead
    in_channels: 4096
    # Only use the last map
    in_index: -1
    num_convs: 2
    dropout_ratio: 0.1
    # in_channel is 4096 (2048 * 2 as we have two frames) as in the original one
    # Predicted residual is 48x48, resize in `decode_head` with `allow_residual_resize`
    # Output dimension is 16 because we need to split to fw and bw
    num_classes: 16
    norm_cfg: *id001
    align_corners: false
    loss_decode:
      type: CrossEntropyLoss
      use_sigmoid: false
      loss_weight: 1.0
  compactness_head:
    type: CompactnessHead
    compact_channel: 0
  w_compactness: 1.0

eval_save: true
# export depends on save
eval_export: true
export_all_seg: true
